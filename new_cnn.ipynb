{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import base64\n",
    "import keras\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done resizing\n"
     ]
    }
   ],
   "source": [
    "# Compress images\n",
    "\n",
    "def resize(folder, fileName):\n",
    "    filePath = os.path.join(folder, fileName)\n",
    "    im = Image.open(filePath)\n",
    "    w, h  = im.size\n",
    "    newIm = im.resize((64, 64))\n",
    "    newIm.save(filePath)\n",
    "\n",
    "def bulkResize(imageFolder):\n",
    "    imgExts = [\"png\", \"jpg\"]\n",
    "    for path, dirs, files in os.walk(imageFolder):\n",
    "        for fileName in files:\n",
    "            ext = fileName[-3:].lower()\n",
    "            if ext not in imgExts:\n",
    "                continue\n",
    "            resize(path, fileName)\n",
    "\n",
    "imageFolder=\"/Users/Chrsitine/Desktop/Conjurers/test_images/\" \n",
    "bulkResize(imageFolder)\n",
    "print(\"Done resizing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  (1124, 64, 64, 3)\n",
      "y_train.shape:  (1124,)\n",
      "x_test.shape:  (82, 64, 64, 3)\n",
      "y_test.shape:  (82,)\n"
     ]
    }
   ],
   "source": [
    "# Load training and testing data \n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "imgExts = [\"png\", \"jpg\"]\n",
    "counter = -1\n",
    "for path, dirs, files in os.walk(\"/Users/Chrsitine/Desktop/Conjurers/images/\"):\n",
    "    for fileName in files:\n",
    "        ext = fileName[-3:].lower()\n",
    "        if ext not in imgExts:\n",
    "            continue\n",
    "        else:\n",
    "            filePath = os.path.join(path, fileName)\n",
    "            img = Image.open(filePath)\n",
    "            img_array = np.array(img.getdata(), np.uint8).reshape(img.size[1], img.size[0], 3)\n",
    "            x_train.append(img_array)\n",
    "            label = np.zeros(13)\n",
    "            label[counter] = 1\n",
    "            # y_train.append(label)\n",
    "            y_train.append(counter)\n",
    "    counter += 1\n",
    "\n",
    "counter = -1\n",
    "for path, dirs, files in os.walk(\"/Users/Chrsitine/Desktop/Conjurers/test_images/\"):\n",
    "    for fileName in files:\n",
    "        ext = fileName[-3:].lower()\n",
    "        if ext not in imgExts:\n",
    "            continue\n",
    "        else:\n",
    "            filePath = os.path.join(path, fileName)\n",
    "            img = Image.open(filePath)\n",
    "            img_array = np.array(img.getdata(), np.uint8).reshape(img.size[1], img.size[0], 3)\n",
    "            x_test.append(img_array)\n",
    "            label = np.zeros(13)\n",
    "            label[counter] = 1\n",
    "            # y_test.append(label)\n",
    "            y_test.append(counter)\n",
    "    counter += 1\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "print(\"x_train.shape: \", x_train.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"x_test.shape: \", x_test.shape)\n",
    "print(\"y_test.shape: \" ,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1124, 64, 64, 3)\n",
      "y_train shape: (1124,)\n",
      "1124 train samples\n",
      "82 test samples\n",
      "Train on 1124 samples, validate on 82 samples\n",
      "Epoch 1/40\n",
      "1124/1124 [==============================] - 20s - loss: 2.6283 - acc: 0.0952 - val_loss: 2.4854 - val_acc: 0.1220\n",
      "Epoch 2/40\n",
      "1124/1124 [==============================] - 19s - loss: 2.3628 - acc: 0.1886 - val_loss: 2.1522 - val_acc: 0.2561\n",
      "Epoch 3/40\n",
      "1124/1124 [==============================] - 18s - loss: 2.1360 - acc: 0.2553 - val_loss: 1.9664 - val_acc: 0.3293\n",
      "Epoch 4/40\n",
      "1124/1124 [==============================] - 19s - loss: 1.8792 - acc: 0.3461 - val_loss: 1.8349 - val_acc: 0.3415\n",
      "Epoch 5/40\n",
      "1124/1124 [==============================] - 18s - loss: 1.6870 - acc: 0.4244 - val_loss: 1.6301 - val_acc: 0.4512\n",
      "Epoch 6/40\n",
      "1124/1124 [==============================] - 18s - loss: 1.3956 - acc: 0.5276 - val_loss: 1.2735 - val_acc: 0.6098\n",
      "Epoch 7/40\n",
      "1124/1124 [==============================] - 21s - loss: 1.1588 - acc: 0.6192 - val_loss: 1.0040 - val_acc: 0.6829\n",
      "Epoch 8/40\n",
      "1124/1124 [==============================] - 21s - loss: 0.9396 - acc: 0.6868 - val_loss: 0.6773 - val_acc: 0.8049\n",
      "Epoch 9/40\n",
      "1124/1124 [==============================] - 21s - loss: 0.7614 - acc: 0.7464 - val_loss: 1.1804 - val_acc: 0.6220\n",
      "Epoch 10/40\n",
      "1124/1124 [==============================] - 20s - loss: 0.6965 - acc: 0.7767 - val_loss: 0.5296 - val_acc: 0.8293\n",
      "Epoch 11/40\n",
      "1124/1124 [==============================] - 18s - loss: 0.5675 - acc: 0.8060 - val_loss: 0.4805 - val_acc: 0.8537\n",
      "Epoch 12/40\n",
      "1124/1124 [==============================] - 18s - loss: 0.5224 - acc: 0.8301 - val_loss: 0.4368 - val_acc: 0.8780\n",
      "Epoch 13/40\n",
      "1124/1124 [==============================] - 16s - loss: 0.4056 - acc: 0.8808 - val_loss: 0.3404 - val_acc: 0.8902\n",
      "Epoch 14/40\n",
      "1124/1124 [==============================] - 16s - loss: 0.3565 - acc: 0.8870 - val_loss: 0.3488 - val_acc: 0.8780\n",
      "Epoch 15/40\n",
      "1124/1124 [==============================] - 17s - loss: 0.3608 - acc: 0.8879 - val_loss: 0.4580 - val_acc: 0.8659\n",
      "Epoch 16/40\n",
      "1124/1124 [==============================] - 17s - loss: 0.3195 - acc: 0.9057 - val_loss: 0.3394 - val_acc: 0.8902\n",
      "Epoch 17/40\n",
      "1124/1124 [==============================] - 16s - loss: 0.2777 - acc: 0.9137 - val_loss: 0.4110 - val_acc: 0.8537\n",
      "Epoch 18/40\n",
      "1124/1124 [==============================] - 16s - loss: 0.2533 - acc: 0.9297 - val_loss: 0.2435 - val_acc: 0.9390\n",
      "Epoch 19/40\n",
      "1124/1124 [==============================] - 16s - loss: 0.2084 - acc: 0.9342 - val_loss: 0.2609 - val_acc: 0.9268\n",
      "Epoch 20/40\n",
      "1124/1124 [==============================] - 16s - loss: 0.2143 - acc: 0.9395 - val_loss: 0.2578 - val_acc: 0.9390\n",
      "Epoch 21/40\n",
      "1124/1124 [==============================] - 16s - loss: 0.1728 - acc: 0.9466 - val_loss: 0.3025 - val_acc: 0.9390\n",
      "Epoch 22/40\n",
      "1124/1124 [==============================] - 17s - loss: 0.1854 - acc: 0.9484 - val_loss: 0.2333 - val_acc: 0.9634\n",
      "Epoch 23/40\n",
      "1124/1124 [==============================] - 17s - loss: 0.1587 - acc: 0.9520 - val_loss: 0.2523 - val_acc: 0.9390\n",
      "Epoch 24/40\n",
      "1124/1124 [==============================] - 16s - loss: 0.1533 - acc: 0.9502 - val_loss: 0.2197 - val_acc: 0.9512\n",
      "Epoch 25/40\n",
      "1124/1124 [==============================] - 16s - loss: 0.1183 - acc: 0.9653 - val_loss: 0.2249 - val_acc: 0.9512\n",
      "Epoch 26/40\n",
      "1124/1124 [==============================] - 17s - loss: 0.1151 - acc: 0.9706 - val_loss: 0.1796 - val_acc: 0.9634\n",
      "Epoch 27/40\n",
      "1124/1124 [==============================] - 17s - loss: 0.1131 - acc: 0.9653 - val_loss: 0.1994 - val_acc: 0.9634\n",
      "Epoch 28/40\n",
      "1124/1124 [==============================] - 17s - loss: 0.1074 - acc: 0.9680 - val_loss: 0.2246 - val_acc: 0.9512\n",
      "Epoch 29/40\n",
      "1124/1124 [==============================] - 17s - loss: 0.0966 - acc: 0.9733 - val_loss: 0.2122 - val_acc: 0.9512\n",
      "Epoch 30/40\n",
      "1124/1124 [==============================] - 17s - loss: 0.0854 - acc: 0.9760 - val_loss: 0.2089 - val_acc: 0.9634\n",
      "Epoch 31/40\n",
      "1124/1124 [==============================] - 16s - loss: 0.0883 - acc: 0.9715 - val_loss: 0.2287 - val_acc: 0.9634\n",
      "Epoch 32/40\n",
      "1124/1124 [==============================] - 17s - loss: 0.0759 - acc: 0.9795 - val_loss: 0.2527 - val_acc: 0.9390\n",
      "Epoch 33/40\n",
      "1124/1124 [==============================] - 17s - loss: 0.0824 - acc: 0.9751 - val_loss: 0.1850 - val_acc: 0.9512\n",
      "Epoch 34/40\n",
      "1124/1124 [==============================] - 16s - loss: 0.0736 - acc: 0.9822 - val_loss: 0.2150 - val_acc: 0.9634\n",
      "Epoch 35/40\n",
      "1124/1124 [==============================] - 16s - loss: 0.0810 - acc: 0.9778 - val_loss: 0.1910 - val_acc: 0.9634\n",
      "Epoch 36/40\n",
      "1124/1124 [==============================] - 19s - loss: 0.0711 - acc: 0.9786 - val_loss: 0.1644 - val_acc: 0.9634\n",
      "Epoch 37/40\n",
      "1124/1124 [==============================] - 17s - loss: 0.0708 - acc: 0.9813 - val_loss: 0.2116 - val_acc: 0.9634\n",
      "Epoch 38/40\n",
      "1124/1124 [==============================] - 17s - loss: 0.0573 - acc: 0.9867 - val_loss: 0.1573 - val_acc: 0.9634\n",
      "Epoch 39/40\n",
      "1124/1124 [==============================] - 17s - loss: 0.0510 - acc: 0.9884 - val_loss: 0.1964 - val_acc: 0.9634\n",
      "Epoch 40/40\n",
      "1124/1124 [==============================] - 17s - loss: 0.0554 - acc: 0.9875 - val_loss: 0.1540 - val_acc: 0.9634\n",
      "Saved trained model\n",
      "82/82 [==============================] - 0s     \n",
      "Test loss:  0.154009104496\n",
      "Test accuracy:  0.963414634146\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "batch_size = 50\n",
    "num_classes = 13\n",
    "epochs = 40\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 64, 64\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "# Save trained model\n",
    "model.save(\"trained_model.hdf5\")\n",
    "model.save_weights(\"trained_weights.hdf5\")\n",
    "print(\"Saved trained model\")\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Test loss: \", score[0])\n",
    "print(\"Test accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred Actual\n",
      "11     0\n",
      "10     1\n",
      "3     5\n",
      "Wrong count:  3\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(x_test, verbose=0)\n",
    "count = 0\n",
    "print(\"Pred Actual\")\n",
    "for i in range(predict.shape[0]):\n",
    "    if np.argmax(predict[i]) != np.argmax(y_test[i]):\n",
    "        print(np.argmax(predict[i]), \"   \", np.argmax(y_test[i]))\n",
    "        count += 1\n",
    "print(\"Wrong count: \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0-indexing with one hot encoding is used for class labels:\n",
    "idx_to_label = {0: \"Coke zero\", 1: \"Oreo thins (original)\", 2: \"Cadbury chocolate fingers\",\n",
    "               3: \"Diet coke\", 4: \"Hershey's drops\", 5: \"m&ms\", 6: \"Sun chips\", \n",
    "               7: \"Sour cream and onion Pringles\", 8: \"Coke (original)\", 9: \"Golden Oreo thins\"}\n",
    "new_idx_to_label = {0: \"apple\", 1: \"bananas\", 2: \"Coke zero\", 3: \"Oreo thins (original)\", \n",
    "                    4: \"Cadbury chocolate fingers\", 5: \"Chex mix\", 6: \"Diet coke\", \n",
    "                    7: \"Hershey's drops\", 8: \"m&ms\", 9: \"Sun chips\", \n",
    "                    10: \"Sour cream and onion Pringles\", 11: \"Coke (original)\", \n",
    "                    12: \"Golden Oreo thins\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model and weights\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"trained_model.hdf5\")\n",
    "model.load_weights(\"trained_weights.hdf5\")\n",
    "print(\"Loaded model and weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
