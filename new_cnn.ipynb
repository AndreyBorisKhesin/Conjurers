{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import base64\n",
    "import keras\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done resizing\n"
     ]
    }
   ],
   "source": [
    "# Compress images\n",
    "\n",
    "def resize(folder, fileName):\n",
    "    filePath = os.path.join(folder, fileName)\n",
    "    im = Image.open(filePath)\n",
    "    w, h  = im.size\n",
    "    newIm = im.resize((64, 64))\n",
    "    newIm.save(filePath)\n",
    "\n",
    "def bulkResize(imageFolder):\n",
    "    imgExts = [\"png\", \"jpg\"]\n",
    "    for path, dirs, files in os.walk(imageFolder):\n",
    "        for fileName in files:\n",
    "            ext = fileName[-3:].lower()\n",
    "            if ext not in imgExts:\n",
    "                continue\n",
    "            resize(path, fileName)\n",
    "\n",
    "imageFolder=\"/Users/Chrsitine/Desktop/Conjurers/images/\" \n",
    "bulkResize(imageFolder)\n",
    "print(\"Done resizing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  (974, 64, 64, 3)\n",
      "y_train.shape:  (974,)\n",
      "x_test.shape:  (70, 64, 64, 3)\n",
      "y_test.shape:  (70,)\n"
     ]
    }
   ],
   "source": [
    "# Load training and testing data \n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "imgExts = [\"png\", \"jpg\"]\n",
    "counter = -1\n",
    "for path, dirs, files in os.walk(\"/Users/Chrsitine/Desktop/Conjurers/images/\"):\n",
    "    for fileName in files:\n",
    "        ext = fileName[-3:].lower()\n",
    "        if ext not in imgExts:\n",
    "            continue\n",
    "        else:\n",
    "            filePath = os.path.join(path, fileName)\n",
    "            img = Image.open(filePath)\n",
    "            img_array = np.array(img.getdata(), np.uint8).reshape(img.size[1], img.size[0], 3)\n",
    "            x_train.append(img_array)\n",
    "            label = np.zeros(10)\n",
    "            label[counter] = 1\n",
    "            # y_train.append(label)\n",
    "            y_train.append(counter)\n",
    "    counter += 1\n",
    "\n",
    "imgExts = [\"png\", \"jpg\"]\n",
    "counter = -1\n",
    "for path, dirs, files in os.walk(\"/Users/Chrsitine/Desktop/Conjurers/test_images/\"):\n",
    "    for fileName in files:\n",
    "        ext = fileName[-3:].lower()\n",
    "        if ext not in imgExts:\n",
    "            continue\n",
    "        else:\n",
    "            filePath = os.path.join(path, fileName)\n",
    "            img = Image.open(filePath)\n",
    "            img_array = np.array(img.getdata(), np.uint8).reshape(img.size[1], img.size[0], 3)\n",
    "            x_test.append(img_array)\n",
    "            label = np.zeros(10)\n",
    "            label[counter] = 1\n",
    "            # y_test.append(label)\n",
    "            y_test.append(counter)\n",
    "    counter += 1\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "print(\"x_train.shape: \", x_train.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"x_test.shape: \", x_test.shape)\n",
    "print(\"y_test.shape: \" ,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (974, 64, 64, 3)\n",
      "y_train shape: (974,)\n",
      "974 train samples\n",
      "70 test samples\n",
      "Train on 974 samples, validate on 70 samples\n",
      "Epoch 1/40\n",
      "974/974 [==============================] - 26s - loss: 2.4869 - acc: 0.1355 - val_loss: 2.1621 - val_acc: 0.1000\n",
      "Epoch 2/40\n",
      "974/974 [==============================] - 26s - loss: 2.0808 - acc: 0.2341 - val_loss: 2.0221 - val_acc: 0.2143\n",
      "Epoch 3/40\n",
      "974/974 [==============================] - 24s - loss: 1.8958 - acc: 0.3183 - val_loss: 1.7298 - val_acc: 0.3571\n",
      "Epoch 4/40\n",
      "974/974 [==============================] - 28s - loss: 1.6650 - acc: 0.4055 - val_loss: 1.4493 - val_acc: 0.5429\n",
      "Epoch 5/40\n",
      "974/974 [==============================] - 19s - loss: 1.3546 - acc: 0.5329 - val_loss: 1.1444 - val_acc: 0.6857\n",
      "Epoch 6/40\n",
      "974/974 [==============================] - 15s - loss: 1.0634 - acc: 0.6417 - val_loss: 1.0746 - val_acc: 0.6286\n",
      "Epoch 7/40\n",
      "974/974 [==============================] - 27s - loss: 0.8536 - acc: 0.7331 - val_loss: 0.8379 - val_acc: 0.7429\n",
      "Epoch 8/40\n",
      "974/974 [==============================] - 24s - loss: 0.7376 - acc: 0.7618 - val_loss: 0.6401 - val_acc: 0.8571\n",
      "Epoch 9/40\n",
      "974/974 [==============================] - 17s - loss: 0.6382 - acc: 0.7977 - val_loss: 0.7804 - val_acc: 0.6857\n",
      "Epoch 10/40\n",
      "974/974 [==============================] - 18s - loss: 0.5250 - acc: 0.8470 - val_loss: 0.7387 - val_acc: 0.7429\n",
      "Epoch 11/40\n",
      "974/974 [==============================] - 22s - loss: 0.4367 - acc: 0.8717 - val_loss: 0.6346 - val_acc: 0.8000\n",
      "Epoch 12/40\n",
      "974/974 [==============================] - 34s - loss: 0.3960 - acc: 0.8727 - val_loss: 0.5212 - val_acc: 0.8714\n",
      "Epoch 13/40\n",
      "974/974 [==============================] - 32s - loss: 0.3293 - acc: 0.8932 - val_loss: 0.4269 - val_acc: 0.8857\n",
      "Epoch 14/40\n",
      "974/974 [==============================] - 21s - loss: 0.2673 - acc: 0.9261 - val_loss: 0.5762 - val_acc: 0.8429\n",
      "Epoch 15/40\n",
      "974/974 [==============================] - 19s - loss: 0.2566 - acc: 0.9343 - val_loss: 0.3974 - val_acc: 0.8714\n",
      "Epoch 16/40\n",
      "974/974 [==============================] - 25s - loss: 0.2348 - acc: 0.9281 - val_loss: 0.4062 - val_acc: 0.8714\n",
      "Epoch 17/40\n",
      "974/974 [==============================] - 22s - loss: 0.2168 - acc: 0.9353 - val_loss: 0.4110 - val_acc: 0.8571\n",
      "Epoch 18/40\n",
      "974/974 [==============================] - 26s - loss: 0.1872 - acc: 0.9425 - val_loss: 0.4427 - val_acc: 0.8714\n",
      "Epoch 19/40\n",
      "974/974 [==============================] - 27s - loss: 0.1643 - acc: 0.9600 - val_loss: 0.4074 - val_acc: 0.8857\n",
      "Epoch 20/40\n",
      "974/974 [==============================] - 22s - loss: 0.1475 - acc: 0.9559 - val_loss: 0.3747 - val_acc: 0.8429\n",
      "Epoch 21/40\n",
      "974/974 [==============================] - 18s - loss: 0.1367 - acc: 0.9620 - val_loss: 0.4168 - val_acc: 0.9000\n",
      "Epoch 22/40\n",
      "974/974 [==============================] - 16s - loss: 0.1104 - acc: 0.9754 - val_loss: 0.4478 - val_acc: 0.8714\n",
      "Epoch 23/40\n",
      "974/974 [==============================] - 17s - loss: 0.1113 - acc: 0.9723 - val_loss: 0.4547 - val_acc: 0.8857\n",
      "Epoch 24/40\n",
      "974/974 [==============================] - 21s - loss: 0.0826 - acc: 0.9774 - val_loss: 0.4660 - val_acc: 0.8857\n",
      "Epoch 25/40\n",
      "974/974 [==============================] - 22s - loss: 0.0986 - acc: 0.9733 - val_loss: 0.4611 - val_acc: 0.8571\n",
      "Epoch 26/40\n",
      "974/974 [==============================] - 24s - loss: 0.0969 - acc: 0.9713 - val_loss: 0.4790 - val_acc: 0.8714\n",
      "Epoch 27/40\n",
      "974/974 [==============================] - 26s - loss: 0.0754 - acc: 0.9815 - val_loss: 0.4338 - val_acc: 0.8714\n",
      "Epoch 28/40\n",
      "974/974 [==============================] - 26s - loss: 0.0753 - acc: 0.9795 - val_loss: 0.4173 - val_acc: 0.8857\n",
      "Epoch 29/40\n",
      "974/974 [==============================] - 29s - loss: 0.0711 - acc: 0.9815 - val_loss: 0.4093 - val_acc: 0.9000\n",
      "Epoch 30/40\n",
      "974/974 [==============================] - 23s - loss: 0.0568 - acc: 0.9918 - val_loss: 0.4933 - val_acc: 0.8857\n",
      "Epoch 31/40\n",
      "974/974 [==============================] - 27s - loss: 0.0590 - acc: 0.9856 - val_loss: 0.4458 - val_acc: 0.9000\n",
      "Epoch 32/40\n",
      "974/974 [==============================] - 20s - loss: 0.0512 - acc: 0.9887 - val_loss: 0.4240 - val_acc: 0.8714\n",
      "Epoch 33/40\n",
      "974/974 [==============================] - 19s - loss: 0.0585 - acc: 0.9815 - val_loss: 0.4761 - val_acc: 0.9000\n",
      "Epoch 34/40\n",
      "974/974 [==============================] - 20s - loss: 0.0529 - acc: 0.9887 - val_loss: 0.4403 - val_acc: 0.8714\n",
      "Epoch 35/40\n",
      "974/974 [==============================] - 21s - loss: 0.0365 - acc: 0.9938 - val_loss: 0.4530 - val_acc: 0.9000\n",
      "Epoch 36/40\n",
      "974/974 [==============================] - 24s - loss: 0.0398 - acc: 0.9918 - val_loss: 0.4503 - val_acc: 0.9000\n",
      "Epoch 37/40\n",
      "974/974 [==============================] - 30s - loss: 0.0414 - acc: 0.9938 - val_loss: 0.4784 - val_acc: 0.8857\n",
      "Epoch 38/40\n",
      "974/974 [==============================] - 29s - loss: 0.0331 - acc: 0.9949 - val_loss: 0.5240 - val_acc: 0.8429\n",
      "Epoch 39/40\n",
      "974/974 [==============================] - 25s - loss: 0.0394 - acc: 0.9918 - val_loss: 0.4827 - val_acc: 0.8571\n",
      "Epoch 40/40\n",
      "974/974 [==============================] - 36s - loss: 0.0346 - acc: 0.9897 - val_loss: 0.4152 - val_acc: 0.9000\n",
      "Saved trained model\n",
      "70/70 [==============================] - 0s     \n",
      "Test loss:  0.415213977076\n",
      "Test accuracy:  0.9\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "batch_size = 56\n",
    "num_classes = 10\n",
    "epochs = 40\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 64, 64\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "# Save trained model\n",
    "model.save('trained_model.hdf5')\n",
    "model.save_weights('trained_weights.hdf5')\n",
    "print(\"Saved trained model\")\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Test loss: \", score[0])\n",
    "print(\"Test accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred Actual\n",
      "3     0\n",
      "5     0\n",
      "3     0\n",
      "2     3\n",
      "0     3\n",
      "4     5\n",
      "3     8\n",
      "Wrong count:  7\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(x_test, verbose=0)\n",
    "count = 0\n",
    "print(\"Pred Actual\")\n",
    "for i in range(predict.shape[0]):\n",
    "    if np.argmax(predict[i]) != np.argmax(y_test[i]):\n",
    "        print(np.argmax(predict[i]), \"   \", np.argmax(y_test[i]))\n",
    "        count += 1\n",
    "print(\"Wrong count: \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0-indexing with one hot encoding is used for class labels:\n",
    "idx_to_label = {0: \"Coke zero\", 1: \"Oreo thins (original)\", 2: \"Cadbury chocolate fingers\",\n",
    "               3: \"Diet coke\", 4: \"Hershey's drops\", 5: \"m&ms\", 6: \"Sun chips\", \n",
    "               7: \"Sour cream and onion Pringles\", 8: \"Coke (original)\", 9: \"Golden Oreo thins\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
