{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import base64\n",
    "import keras\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done resizing\n"
     ]
    }
   ],
   "source": [
    "# Compress images\n",
    "\n",
    "def resize(folder, fileName):\n",
    "    filePath = os.path.join(folder, fileName)\n",
    "    im = Image.open(filePath)\n",
    "    w, h  = im.size\n",
    "    newIm = im.resize((64, 64))\n",
    "    newIm.save(filePath)\n",
    "\n",
    "def bulkResize(imageFolder):\n",
    "    imgExts = [\"png\", \"jpg\"]\n",
    "    for path, dirs, files in os.walk(imageFolder):\n",
    "        for fileName in files:\n",
    "            ext = fileName[-3:].lower()\n",
    "            if ext not in imgExts:\n",
    "                continue\n",
    "            resize(path, fileName)\n",
    "\n",
    "imageFolder=\"/Users/Chrsitine/Desktop/Conjurers/images/\" \n",
    "bulkResize(imageFolder)\n",
    "print(\"Done resizing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0-indexing with one hot encoding is used for class labels:\n",
    "idx_to_label = {0: \"Coke zero\", 1: \"Oreo thins (original)\", 2: \"Cadbury chocolate fingers\",\n",
    "               3: \"Diet coke\", 4: \"Hershey's drops\", 5: \"m&ms\", 6: \"Sun chips\", \n",
    "               7: \"Sour cream and onion Pringles\", 8: \"Coke (original)\", 9: \"Golden Oreo thins\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  (550, 64, 64, 3)\n",
      "y_train.shape:  (550,)\n",
      "x_test.shape:  (10, 64, 64, 3)\n",
      "y_test.shape:  (10,)\n"
     ]
    }
   ],
   "source": [
    "# Load training and testing data \n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "imgExts = [\"png\", \"jpg\"]\n",
    "counter = -1\n",
    "for path, dirs, files in os.walk(\"/Users/Chrsitine/Desktop/Conjurers/images/\"):\n",
    "    for fileName in files:\n",
    "        ext = fileName[-3:].lower()\n",
    "        if ext not in imgExts:\n",
    "            continue\n",
    "        else:\n",
    "            filePath = os.path.join(path, fileName)\n",
    "            img = Image.open(filePath)\n",
    "            img_array = np.array(img.getdata(), np.uint8).reshape(img.size[1], img.size[0], 3)\n",
    "            x_train.append(img_array)\n",
    "            label = np.zeros(10)\n",
    "            label[counter] = 1\n",
    "            # y_train.append(label)\n",
    "            y_train.append(counter)\n",
    "    counter += 1\n",
    "\n",
    "imgExts = [\"png\", \"jpg\"]\n",
    "counter = -1\n",
    "for path, dirs, files in os.walk(\"/Users/Chrsitine/Desktop/Conjurers/test_images/\"):\n",
    "    for fileName in files:\n",
    "        ext = fileName[-3:].lower()\n",
    "        if ext not in imgExts:\n",
    "            continue\n",
    "        else:\n",
    "            filePath = os.path.join(path, fileName)\n",
    "            img = Image.open(filePath)\n",
    "            img_array = np.array(img.getdata(), np.uint8).reshape(img.size[1], img.size[0], 3)\n",
    "            x_test.append(img_array)\n",
    "            label = np.zeros(10)\n",
    "            label[counter] = 1\n",
    "            # y_test.append(label)\n",
    "            y_test.append(counter)\n",
    "    counter += 1\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "print(\"x_train.shape: \", x_train.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"x_test.shape: \", x_test.shape)\n",
    "print(\"y_test.shape: \" ,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (550, 64, 64, 3)\n",
      "y_train shape: (550,)\n",
      "550 train samples\n",
      "10 test samples\n",
      "Train on 550 samples, validate on 10 samples\n",
      "Epoch 1/40\n",
      "550/550 [==============================] - 10s - loss: 2.5351 - acc: 0.1127 - val_loss: 2.2575 - val_acc: 0.1000\n",
      "Epoch 2/40\n",
      "550/550 [==============================] - 9s - loss: 2.2761 - acc: 0.1255 - val_loss: 2.2047 - val_acc: 0.3000\n",
      "Epoch 3/40\n",
      "550/550 [==============================] - 9s - loss: 2.1845 - acc: 0.2000 - val_loss: 2.1720 - val_acc: 0.2000\n",
      "Epoch 4/40\n",
      "550/550 [==============================] - 10s - loss: 2.1065 - acc: 0.2345 - val_loss: 2.0651 - val_acc: 0.2000\n",
      "Epoch 5/40\n",
      "550/550 [==============================] - 9s - loss: 2.0781 - acc: 0.2636 - val_loss: 1.8141 - val_acc: 0.6000\n",
      "Epoch 6/40\n",
      "550/550 [==============================] - 9s - loss: 1.8056 - acc: 0.3655 - val_loss: 1.5705 - val_acc: 0.3000\n",
      "Epoch 7/40\n",
      "550/550 [==============================] - 10s - loss: 1.8584 - acc: 0.3491 - val_loss: 1.7799 - val_acc: 0.3000\n",
      "Epoch 8/40\n",
      "550/550 [==============================] - 10s - loss: 1.6413 - acc: 0.4109 - val_loss: 1.4966 - val_acc: 0.6000\n",
      "Epoch 9/40\n",
      "550/550 [==============================] - 11s - loss: 1.4771 - acc: 0.4964 - val_loss: 1.3296 - val_acc: 0.7000\n",
      "Epoch 10/40\n",
      "550/550 [==============================] - 11s - loss: 1.3935 - acc: 0.5273 - val_loss: 1.3517 - val_acc: 0.7000\n",
      "Epoch 11/40\n",
      "550/550 [==============================] - 8s - loss: 1.1553 - acc: 0.6527 - val_loss: 0.9802 - val_acc: 0.8000\n",
      "Epoch 12/40\n",
      "550/550 [==============================] - 9s - loss: 1.1818 - acc: 0.6236 - val_loss: 0.8876 - val_acc: 0.8000\n",
      "Epoch 13/40\n",
      "550/550 [==============================] - 8s - loss: 0.9453 - acc: 0.7200 - val_loss: 1.3926 - val_acc: 0.6000\n",
      "Epoch 14/40\n",
      "550/550 [==============================] - 10s - loss: 0.9917 - acc: 0.6945 - val_loss: 0.7751 - val_acc: 0.8000\n",
      "Epoch 15/40\n",
      "550/550 [==============================] - 10s - loss: 0.7811 - acc: 0.7564 - val_loss: 0.8900 - val_acc: 0.7000\n",
      "Epoch 16/40\n",
      "550/550 [==============================] - 13s - loss: 0.8057 - acc: 0.7509 - val_loss: 0.8654 - val_acc: 0.8000\n",
      "Epoch 17/40\n",
      "550/550 [==============================] - 13s - loss: 0.5714 - acc: 0.8364 - val_loss: 0.5567 - val_acc: 0.8000\n",
      "Epoch 18/40\n",
      "550/550 [==============================] - 13s - loss: 0.5792 - acc: 0.8273 - val_loss: 0.5310 - val_acc: 0.9000\n",
      "Epoch 19/40\n",
      "550/550 [==============================] - 13s - loss: 0.5081 - acc: 0.8527 - val_loss: 0.4723 - val_acc: 0.9000\n",
      "Epoch 20/40\n",
      "550/550 [==============================] - 12s - loss: 0.4534 - acc: 0.8582 - val_loss: 0.3476 - val_acc: 0.8000\n",
      "Epoch 21/40\n",
      "550/550 [==============================] - 11s - loss: 0.4180 - acc: 0.8836 - val_loss: 0.5184 - val_acc: 0.8000\n",
      "Epoch 22/40\n",
      "550/550 [==============================] - 10s - loss: 0.4177 - acc: 0.8855 - val_loss: 0.4436 - val_acc: 0.9000\n",
      "Epoch 23/40\n",
      "550/550 [==============================] - 9s - loss: 0.3882 - acc: 0.8891 - val_loss: 0.4423 - val_acc: 0.9000\n",
      "Epoch 24/40\n",
      "550/550 [==============================] - 10s - loss: 0.3222 - acc: 0.9164 - val_loss: 0.4809 - val_acc: 0.8000\n",
      "Epoch 25/40\n",
      "550/550 [==============================] - 12s - loss: 0.3164 - acc: 0.9236 - val_loss: 0.5563 - val_acc: 0.8000\n",
      "Epoch 26/40\n",
      "550/550 [==============================] - 12s - loss: 0.3641 - acc: 0.9091 - val_loss: 0.4637 - val_acc: 0.9000\n",
      "Epoch 27/40\n",
      "550/550 [==============================] - 13s - loss: 0.2876 - acc: 0.9345 - val_loss: 0.6773 - val_acc: 0.8000\n",
      "Epoch 28/40\n",
      "550/550 [==============================] - 13s - loss: 0.2553 - acc: 0.9382 - val_loss: 0.4934 - val_acc: 0.8000\n",
      "Epoch 29/40\n",
      "550/550 [==============================] - 13s - loss: 0.2135 - acc: 0.9455 - val_loss: 0.5407 - val_acc: 0.8000\n",
      "Epoch 30/40\n",
      "550/550 [==============================] - 13s - loss: 0.2152 - acc: 0.9509 - val_loss: 0.6001 - val_acc: 0.8000\n",
      "Epoch 31/40\n",
      "550/550 [==============================] - 15s - loss: 0.2074 - acc: 0.9455 - val_loss: 0.4308 - val_acc: 0.9000\n",
      "Epoch 32/40\n",
      "550/550 [==============================] - 10s - loss: 0.1722 - acc: 0.9618 - val_loss: 0.8723 - val_acc: 0.8000\n",
      "Epoch 33/40\n",
      "550/550 [==============================] - 11s - loss: 0.1772 - acc: 0.9655 - val_loss: 0.5434 - val_acc: 0.8000\n",
      "Epoch 34/40\n",
      "550/550 [==============================] - 10s - loss: 0.1833 - acc: 0.9600 - val_loss: 0.6038 - val_acc: 0.8000\n",
      "Epoch 35/40\n",
      "550/550 [==============================] - 11s - loss: 0.1485 - acc: 0.9636 - val_loss: 0.7841 - val_acc: 0.8000\n",
      "Epoch 36/40\n",
      "550/550 [==============================] - 10s - loss: 0.1518 - acc: 0.9636 - val_loss: 0.7938 - val_acc: 0.8000\n",
      "Epoch 37/40\n",
      "550/550 [==============================] - 10s - loss: 0.1398 - acc: 0.9709 - val_loss: 0.6828 - val_acc: 0.8000\n",
      "Epoch 38/40\n",
      "550/550 [==============================] - 10s - loss: 0.1619 - acc: 0.9491 - val_loss: 0.5643 - val_acc: 0.8000\n",
      "Epoch 39/40\n",
      "550/550 [==============================] - 10s - loss: 0.1351 - acc: 0.9782 - val_loss: 0.5460 - val_acc: 0.8000\n",
      "Epoch 40/40\n",
      "550/550 [==============================] - 9s - loss: 0.1303 - acc: 0.9691 - val_loss: 0.4324 - val_acc: 0.9000\n",
      "Saved trained model\n",
      "10/10 [==============================] - 0s\n",
      "Test loss:  0.432436555624\n",
      "Test accuracy:  0.899999976158\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "batch_size = 56\n",
    "num_classes = 10\n",
    "epochs = 40\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 64, 64\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "# Save trained model\n",
    "model.save('trained_model.hdf5')\n",
    "model.save_weights('trained_weights.hdf5')\n",
    "print(\"Saved trained model\")\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Test loss: \", score[0])\n",
    "print(\"Test accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.95562983e-01,   1.88833605e-02,   1.09651862e-02,\n",
       "          5.21037094e-02,   1.05420448e-01,   1.52213452e-02,\n",
       "          5.66586386e-05,   1.44844991e-03,   2.39636487e-04,\n",
       "          9.81707199e-05],\n",
       "       [  4.27160239e-06,   9.99953270e-01,   3.53988653e-05,\n",
       "          6.88802629e-06,   2.18352767e-08,   2.89381887e-08,\n",
       "          6.83768209e-10,   2.68876005e-10,   6.12759337e-08,\n",
       "          9.50732115e-09],\n",
       "       [  1.24132663e-01,   2.44672392e-02,   8.49384844e-01,\n",
       "          1.87580287e-03,   2.39116360e-07,   1.25211627e-05,\n",
       "          7.18544561e-06,   1.14374291e-06,   1.15605690e-04,\n",
       "          2.78823291e-06],\n",
       "       [  6.43543480e-03,   1.24299561e-03,   1.78609462e-05,\n",
       "          2.84072328e-02,   1.87845799e-05,   8.74167963e-05,\n",
       "          8.36183038e-03,   1.89294551e-05,   9.55389261e-01,\n",
       "          2.03162053e-05],\n",
       "       [  1.36764036e-04,   2.17551395e-04,   1.00692259e-05,\n",
       "          2.19306414e-04,   9.99263585e-01,   4.91980209e-05,\n",
       "          4.67419241e-08,   7.38566669e-05,   1.16318176e-07,\n",
       "          2.95712052e-05],\n",
       "       [  1.84993297e-02,   9.58766881e-03,   2.49623996e-03,\n",
       "          2.36637611e-03,   5.46880253e-03,   9.57638323e-01,\n",
       "          8.94243945e-04,   2.54118320e-04,   4.83867159e-04,\n",
       "          2.31098849e-03],\n",
       "       [  1.34292243e-16,   1.13836794e-12,   8.01127827e-14,\n",
       "          8.99924319e-12,   4.37109023e-16,   2.17840459e-14,\n",
       "          9.99999166e-01,   3.40115869e-12,   9.27786488e-08,\n",
       "          7.33276636e-07],\n",
       "       [  7.70864123e-03,   2.54832301e-03,   2.20401780e-04,\n",
       "          3.62191611e-04,   2.45136637e-02,   1.50710106e-01,\n",
       "          2.15191790e-03,   7.45413065e-01,   8.37794723e-05,\n",
       "          6.62878826e-02],\n",
       "       [  7.15332106e-04,   1.40734119e-04,   3.32811692e-06,\n",
       "          3.58898868e-03,   2.82979215e-07,   4.38195675e-05,\n",
       "          8.29277653e-03,   5.56003033e-06,   9.87192750e-01,\n",
       "          1.64334197e-05],\n",
       "       [  6.57505734e-05,   3.84630781e-04,   3.46563756e-05,\n",
       "          9.93782523e-05,   6.99589867e-03,   5.68105497e-06,\n",
       "          1.71512092e-05,   1.27170319e-02,   4.07627176e-08,\n",
       "          9.79679763e-01]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
