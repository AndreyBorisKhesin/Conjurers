{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import base64\n",
    "import keras\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import skimage.data\n",
    "import skimage.transform\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress images\n",
    "\n",
    "def resize(folder, fileName):\n",
    "    filePath = os.path.join(folder, fileName)\n",
    "    im = Image.open(filePath)\n",
    "    w, h  = im.size\n",
    "    newIm = im.resize((64, 64))\n",
    "    newIm.save(filePath)\n",
    "\n",
    "def bulkResize(imageFolder):\n",
    "    imgExts = [\"png\", \"jpg\"]\n",
    "    for path, dirs, files in os.walk(imageFolder):\n",
    "        for fileName in files:\n",
    "            ext = fileName[-3:].lower()\n",
    "            if ext not in imgExts:\n",
    "                continue\n",
    "            resize(path, fileName)\n",
    "\n",
    "#imageFolder=\"/Users/Chrsitine/Desktop/Conjurers/images/yellow_oreos/\" \n",
    "bulkResize(imageFolder)\n",
    "print(\"Done resizing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0-indexing with one hot encoding is used for class labels:\n",
    "idx_to_label = {0: \"Coke zero\", 1: \"Oreo thins (original)\", 2: \"Cadbury chocolate fingers\",\n",
    "               3: \"Diet coke\", 4: \"Hershey's drops\", 5: \"m&ms\", 6: \"Sun chips\", \n",
    "               7: \"Sour cream and onion Pringles\", 8: \"Coke (original)\", 9: \"Golden Oreo thins\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 64, 64, 3)\n",
      "(550,)\n"
     ]
    }
   ],
   "source": [
    "# Load training and testing data \n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "train_images = []\n",
    "test_images = []\n",
    "labels = []\n",
    "\n",
    "imgExts = [\"png\", \"jpg\"]\n",
    "counter = -1\n",
    "for path, dirs, files in os.walk(\"/Users/Chrsitine/Desktop/Conjurers/images/\"):\n",
    "    for fileName in files:\n",
    "        ext = fileName[-3:].lower()\n",
    "        if ext not in imgExts:\n",
    "            continue\n",
    "        else:\n",
    "            filePath = os.path.join(path, fileName)\n",
    "            img = Image.open(filePath)\n",
    "            img_array = np.array(img.getdata(), np.uint8).reshape(img.size[1], img.size[0], 3)\n",
    "            x_train.append(img_array)\n",
    "            train_images.append(skimage.data.imread(filePath))\n",
    "            y_train.append(counter)\n",
    "            label = np.zeros(10)\n",
    "            label[counter] = 1\n",
    "            #y_train.append(label)\n",
    "    counter += 1\n",
    "\n",
    "imgExts = [\"png\", \"jpg\"]\n",
    "counter = -1\n",
    "for path, dirs, files in os.walk(\"/Users/Chrsitine/Desktop/Conjurers/test_images/\"):\n",
    "    for fileName in files:\n",
    "        ext = fileName[-3:].lower()\n",
    "        if ext not in imgExts:\n",
    "            continue\n",
    "        else:\n",
    "            filePath = os.path.join(path, fileName)\n",
    "            img = Image.open(filePath)\n",
    "            img_array = np.array(img.getdata(), np.uint8).reshape(img.size[1], img.size[0], 3)\n",
    "            x_test.append(img_array)\n",
    "            test_images.append(skimage.data.imread(filePath))\n",
    "            label = np.zeros(10)\n",
    "            label[counter] = 1\n",
    "            y_test.append(counter)\n",
    "    counter += 1\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116fa3b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118198470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116f9b278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_images_and_labels(images, labels):\n",
    "    \"\"\"Display the first image of each label.\"\"\"\n",
    "    unique_labels = set(labels)\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    i = 1\n",
    "    for label in unique_labels:\n",
    "        # Pick the first image for each label.\n",
    "        image = images[labels.index(label)]\n",
    "        plt.subplot(2, 5, i)  # A grid of 8 rows x 8 columns\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Label {0} ({1})\".format(label, labels.count(label)))\n",
    "        i += 1\n",
    "        _ = plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "display_images_and_labels(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_flat:  Tensor(\"Flatten/flatten/Reshape:0\", shape=(?, 12288), dtype=float32)\n",
      "logits:  Tensor(\"fully_connected/Relu:0\", shape=(?, 62), dtype=float32)\n",
      "loss:  Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "predicted_labels:  Tensor(\"ArgMax:0\", shape=(?,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Create a graph to hold the model.\n",
    "graph = tf.Graph()\n",
    "\n",
    "# Create model in the graph.\n",
    "with graph.as_default():\n",
    "    # Placeholders for inputs and labels.\n",
    "    images_ph = tf.placeholder(tf.float32, [None, 64, 64, 3])\n",
    "    labels_ph = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "    # Flatten input from: [None, height, width, channels]\n",
    "    # To: [None, height * width * channels] == [None, 3072]\n",
    "    images_flat = tf.contrib.layers.flatten(images_ph)\n",
    "\n",
    "    # Fully connected layer. \n",
    "    # Generates logits of size [None, 62]\n",
    "    logits = tf.contrib.layers.fully_connected(images_flat, 62, tf.nn.relu)\n",
    "\n",
    "    # Convert logits to label indexes (int).\n",
    "    # Shape [None], which is a 1D vector of length == batch_size.\n",
    "    predicted_labels = tf.argmax(logits, 1)\n",
    "\n",
    "    # Define the loss function. \n",
    "    # Cross-entropy is a good choice for classification.\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels_ph))\n",
    "\n",
    "    # Create training op.\n",
    "    train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "    # And, finally, an initialization op to execute before training.\n",
    "    # TODO: rename to tf.global_variables_initializer() on TF 0.12.\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "print(\"images_flat: \", images_flat)\n",
    "print(\"logits: \", logits)\n",
    "print(\"loss: \", loss)\n",
    "print(\"predicted_labels: \", predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a session to run the graph we created.\n",
    "session = tf.Session(graph=graph)\n",
    "\n",
    "# First step is always to initialize all variables. \n",
    "# We don't care about the return value, though. It's None.\n",
    "_ = session.run([init])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  4.12714\n",
      "Loss:  4.12714\n",
      "Loss:  4.12714\n",
      "Loss:  4.12714\n",
      "Loss:  4.12714\n",
      "Loss:  4.12714\n",
      "Loss:  4.12714\n",
      "Loss:  4.12714\n",
      "Loss:  4.12714\n",
      "Loss:  4.12714\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    _, loss_value = session.run([train, loss], \n",
    "                                feed_dict={images_ph: x_train, labels_ph: labels})\n",
    "    if i % 10 == 0:\n",
    "        print(\"Loss: \", loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(?, 64, 64, 3), dtype=float32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1063\u001b[0m             subfeed_t = self.graph.as_graph_element(subfeed, allow_tensor=True,\n\u001b[0;32m-> 1064\u001b[0;31m                                                     allow_operation=False)\n\u001b[0m\u001b[1;32m   1065\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3034\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3035\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3113\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3114\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3115\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"Placeholder:0\", shape=(?, 64, 64, 3), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-2667a42dc206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run predictions against the full test set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m predicted = session.run([predicted_labels], \n\u001b[0;32m----> 3\u001b[0;31m                         feed_dict={images_ph: test_images})[0]\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Calculate how many matches we got.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmatch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1065\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m             raise TypeError('Cannot interpret feed_dict key as Tensor: '\n\u001b[0;32m-> 1067\u001b[0;31m                             + e.args[0])\n\u001b[0m\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder:0\", shape=(?, 64, 64, 3), dtype=float32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "# Run predictions against the full test set.\n",
    "predicted = session.run([predicted_labels], \n",
    "                        feed_dict={images_ph: test_images})[0]\n",
    "# Calculate how many matches we got.\n",
    "match_count = sum([int(y == y_) for y, y_ in zip(y_test, predicted)])\n",
    "accuracy = match_count / len(y_test)\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model.save(\"trained_model1.hdf5\")\n",
    "model.save_weights(\"trained_weights1.hdf5\")\n",
    "print(\"Saved trained model and weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
